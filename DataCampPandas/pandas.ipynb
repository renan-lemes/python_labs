{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.sort_values('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[['seleciona']]\n",
    "# colors = [\"brown\", \"black\", \"tan\"]\n",
    "# condition = dogs[\"color\"].isin(colors)\n",
    "# dogs[condition]\n",
    "# \n",
    "\n",
    "#colors = [\"brown\", \"black\", \"tan\"]\n",
    "#condition = dogs[\"color\"].isin(colors)\n",
    "#dogs[condition]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Mojave Desert states\n",
    "#canu = [\"California\", \"Arizona\", \"Nevada\", \"Utah\"]\n",
    "\n",
    "# Filter for rows in the Mojave Desert states\n",
    "#mojave_homelessness = homelessness[homelessness[\"state\"].isin(canu)]\n",
    "\n",
    "# See the result\n",
    "#print(mojave_homelessness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' homelessness[\"indiv_per_10k\"] = 10000 * homelessness[\"individuals\"] / homelessness[\"state_pop\"] \\n\\n# Subset rows for indiv_per_10k greater than 20\\nhigh_homelessness = homelessness[homelessness[\"indiv_per_10k\"] > 20]\\n\\n# Sort high_homelessness by descending indiv_per_10k\\nhigh_homelessness_srt = high_homelessness.sort_values(\"indiv_per_10k\", ascending=False)\\n\\n# From high_homelessness_srt, select the state and indiv_per_10k cols\\nresult = high_homelessness_srt[[\"state\", \"indiv_per_10k\"]]\\n\\n# See the result\\nprint(result) '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create indiv_per_10k col as homeless individuals per 10k state pop\n",
    "''' homelessness[\"indiv_per_10k\"] = 10000 * homelessness[\"individuals\"] / homelessness[\"state_pop\"] \n",
    "\n",
    "# Subset rows for indiv_per_10k greater than 20\n",
    "high_homelessness = homelessness[homelessness[\"indiv_per_10k\"] > 20]\n",
    "\n",
    "# Sort high_homelessness by descending indiv_per_10k\n",
    "high_homelessness_srt = high_homelessness.sort_values(\"indiv_per_10k\", ascending=False)\n",
    "\n",
    "# From high_homelessness_srt, select the state and indiv_per_10k cols\n",
    "result = high_homelessness_srt[[\"state\", \"indiv_per_10k\"]]\n",
    "\n",
    "# See the result\n",
    "print(result) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    agregação de dados\\n    df[\\'column\\'].agg(function)\\n    \\n    # A custom IQR function\\n    def iqr(column):\\n        return column.quantile(0.75) - column.quantile(0.25)\\n    \\n    # Print IQR of the temperature_c column\\n    print(sales[\"temperature_c\"].agg(iqr))\\n\\n    # A custom IQR function\\n    def iqr(column):\\n        return column.quantile(0.75) - column.quantile(0.25)\\n\\n    # Update to print IQR of temperature_c, fuel_price_usd_per_l, & unemployment\\n    print(sales[[\"temperature_c\", \\'fuel_price_usd_per_l\\', \\'unemployment\\']].agg(iqr))\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    agregação de dados\n",
    "    df['column'].agg(function)\n",
    "    \n",
    "    # A custom IQR function\n",
    "    def iqr(column):\n",
    "        return column.quantile(0.75) - column.quantile(0.25)\n",
    "    \n",
    "    # Print IQR of the temperature_c column\n",
    "    print(sales[\"temperature_c\"].agg(iqr))\n",
    "\n",
    "    # A custom IQR function\n",
    "    def iqr(column):\n",
    "        return column.quantile(0.75) - column.quantile(0.25)\n",
    "\n",
    "    # Update to print IQR of temperature_c, fuel_price_usd_per_l, & unemployment\n",
    "    print(sales[[\"temperature_c\", 'fuel_price_usd_per_l', 'unemployment']].agg(iqr))\n",
    "\n",
    "    print(sales[[\"temperature_c\", \"fuel_price_usd_per_l\", \"unemployment\"]].agg([iqr, np.median]))\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n# Sort sales_1_1 by date\\nsales_1_1 = sales_1_1.sort_values(\"date\")\\n\\n# Get the cumulative sum of weekly_sales, add as cum_weekly_sales col\\nsales_1_1[\"cum_weekly_sales\"] = sales_1_1[\"weekly_sales\"].cumsum()\\n\\n# Get the cumulative max of weekly_sales, add as cum_max_sales col\\nsales_1_1[\"cum_max_sales\"] = sales_1_1[\"weekly_sales\"].cummax()\\n\\n# See the columns you calculated\\nprint(sales_1_1[[\"date\", \"weekly_sales\", \"cum_weekly_sales\", \"cum_max_sales\"]])\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "# Sort sales_1_1 by date\n",
    "sales_1_1 = sales_1_1.sort_values(\"date\")\n",
    "\n",
    "# Get the cumulative sum of weekly_sales, add as cum_weekly_sales col\n",
    "sales_1_1[\"cum_weekly_sales\"] = sales_1_1[\"weekly_sales\"].cumsum()\n",
    "\n",
    "# Get the cumulative max of weekly_sales, add as cum_max_sales col\n",
    "sales_1_1[\"cum_max_sales\"] = sales_1_1[\"weekly_sales\"].cummax()\n",
    "\n",
    "# See the columns you calculated\n",
    "print(sales_1_1[[\"date\", \"weekly_sales\", \"cum_weekly_sales\", \"cum_max_sales\"]])\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\n    # Drop duplicate store/type combinations\\n    store_types = sales.drop_duplicates(subset='store')\\n    print(store_types.head())\\n\\n    # Drop duplicate store/department combinations\\n    store_depts = sales.drop_duplicates(subset=['department', 'store'])\\n    print(store_depts.head())\\n\\n    # Subset the rows where is_holiday is True and drop duplicate dates\\n    holiday_dates = sales[sales['is_holiday']].drop_duplicates(subset='date')\\n\\n    # Print date col of holiday_dates\\n    print(holiday_dates.head())\\n\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "    # Drop duplicate store/type combinations\n",
    "    store_types = sales.drop_duplicates(subset='store')\n",
    "    print(store_types.head())\n",
    "\n",
    "    # Drop duplicate store/department combinations\n",
    "    store_depts = sales.drop_duplicates(subset=['department', 'store'])\n",
    "    print(store_depts.head())\n",
    "\n",
    "    # Subset the rows where is_holiday is True and drop duplicate dates\n",
    "    holiday_dates = sales[sales['is_holiday']].drop_duplicates(subset='date')\n",
    "\n",
    "    # Print date col of holiday_dates\n",
    "    print(holiday_dates.head())\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\n    # Count the number of stores of each type\\n    store_counts = store_types['type'].value_counts()\\n    print(store_counts)\\n\\n    # Get the proportion of stores of each type\\n    store_props = store_types['type'].value_counts(normalize=True)\\n    print(store_props)\\n\\n    # Count the number of each department number and sort\\n    dept_counts_sorted = store_depts['department'].value_counts(sort=True)\\n    print(dept_counts_sorted)\\n\\n    # Get the proportion of departments of each number and sort\\n    dept_props_sorted = store_depts['department'].value_counts(sort=True, normalize=True)\\n    print(dept_props_sorted)\\n\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "    # Count the number of stores of each type\n",
    "    store_counts = store_types['type'].value_counts()\n",
    "    print(store_counts)\n",
    "\n",
    "    # Get the proportion of stores of each type\n",
    "    store_props = store_types['type'].value_counts(normalize=True)\n",
    "    print(store_props)\n",
    "\n",
    "    # Count the number of each department number and sort\n",
    "    dept_counts_sorted = store_depts['department'].value_counts(sort=True)\n",
    "    print(dept_counts_sorted)\n",
    "\n",
    "    # Get the proportion of departments of each number and sort\n",
    "    dept_props_sorted = store_depts['department'].value_counts(sort=True, normalize=True)\n",
    "    print(dept_props_sorted)\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n    # Calc total weekly sales\\n    sales_all = sales[\"weekly_sales\"].sum()\\n\\n    # Subset for type A stores, calc total weekly sales\\n    sales_A = sales[sales[\"type\"] == \"A\"][\"weekly_sales\"].sum()\\n\\n    # Subset for type B stores, calc total weekly sales\\n    sales_B = sales[sales[\\'type\\']== \\'B\\'][\\'weekly_sales\\'].sum()\\n\\n    # Subset for type C stores, calc total weekly sales\\n    sales_C = sales[sales[\\'type\\']== \\'C\\'][\\'weekly_sales\\'].sum()\\n\\n    # Get proportion for each type\\n    sales_propn_by_type = [sales_A, sales_B, sales_C] / sales_all\\n    print(sales_propn_by_type)\\n\\n   # From previous step\\n    sales_by_type = sales.groupby(\"type\")[\"weekly_sales\"].sum()\\n\\n    # Group by type and is_holiday; calc total weekly sales\\n    sales_by_type_is_holiday = sales.groupby([\"type\", \"is_holiday\"])[\"weekly_sales\"].sum()\\n    print(sales_by_type_is_holiday)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "    # Calc total weekly sales\n",
    "    sales_all = sales[\"weekly_sales\"].sum()\n",
    "\n",
    "    # Subset for type A stores, calc total weekly sales\n",
    "    sales_A = sales[sales[\"type\"] == \"A\"][\"weekly_sales\"].sum()\n",
    "\n",
    "    # Subset for type B stores, calc total weekly sales\n",
    "    sales_B = sales[sales['type']== 'B']['weekly_sales'].sum()\n",
    "\n",
    "    # Subset for type C stores, calc total weekly sales\n",
    "    sales_C = sales[sales['type']== 'C']['weekly_sales'].sum()\n",
    "\n",
    "    # Get proportion for each type\n",
    "    sales_propn_by_type = [sales_A, sales_B, sales_C] / sales_all\n",
    "    print(sales_propn_by_type)\n",
    "\n",
    "   # From previous step\n",
    "    sales_by_type = sales.groupby(\"type\")[\"weekly_sales\"].sum()\n",
    "\n",
    "    # Group by type and is_holiday; calc total weekly sales\n",
    "    sales_by_type_is_holiday = sales.groupby([\"type\", \"is_holiday\"])[\"weekly_sales\"].sum()\n",
    "    print(sales_by_type_is_holiday)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n    # Import numpy with the alias np\\n    import numpy as np\\n\\n    # For each store type, aggregate weekly_sales: get min, max, mean, and median\\n    sales_stats = sales.groupby(\"type\")[\"weekly_sales\"].agg([np.min, np.max, np.mean, np.median])\\n\\n    # Print sales_stats\\n    print(sales_stats)\\n\\n    # For each store type, aggregate unemployment and fuel_price_usd_per_l: get min, max, mean, and median\\n    unemp_fuel_stats = sales.groupby(\"type\")[[\"unemployment\", \"fuel_price_usd_per_l\"]].agg([np.min, np.max, np.mean, np.median])\\n\\n    # Print unemp_fuel_stats\\n    print(unemp_fuel_stats)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "    # Import numpy with the alias np\n",
    "    import numpy as np\n",
    "\n",
    "    # For each store type, aggregate weekly_sales: get min, max, mean, and median\n",
    "    sales_stats = sales.groupby(\"type\")[\"weekly_sales\"].agg([np.min, np.max, np.mean, np.median])\n",
    "\n",
    "    # Print sales_stats\n",
    "    print(sales_stats)\n",
    "\n",
    "    # For each store type, aggregate unemployment and fuel_price_usd_per_l: get min, max, mean, and median\n",
    "    unemp_fuel_stats = sales.groupby(\"type\")[[\"unemployment\", \"fuel_price_usd_per_l\"]].agg([np.min, np.max, np.mean, np.median])\n",
    "\n",
    "    # Print unemp_fuel_stats\n",
    "    print(unemp_fuel_stats)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\n    # Import NumPy as np\\n    import numpy as np\\n\\n    # Pivot for mean and median weekly_sales for each store type\\n    mean_med_sales_by_type = sales.pivot_table(values='weekly_sales',index='type', aggfunc=[np.median, np.mean])\\n\\n    # Print mean_med_sales_by_type\\n    print(mean_med_sales_by_type)\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "    # Import NumPy as np\n",
    "    import numpy as np\n",
    "\n",
    "    # Pivot for mean and median weekly_sales for each store type\n",
    "    mean_med_sales_by_type = sales.pivot_table(values='weekly_sales',index='type', aggfunc=[np.median, np.mean])\n",
    "\n",
    "    # Print mean_med_sales_by_type\n",
    "    print(mean_med_sales_by_type)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" mean_sales_by_type_holiday = sales.pivot_table(\\n    values=['weekly_sales', 'is_holiday'], index='type')\\n\\n    # Print mean_sales_by_type_holiday\\n    print(mean_sales_by_type_holiday) \\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' mean_sales_by_type_holiday = sales.pivot_table(\n",
    "    values=['weekly_sales', 'is_holiday'], index='type')\n",
    "\n",
    "    # Print mean_sales_by_type_holiday\n",
    "    print(mean_sales_by_type_holiday) \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" # Pivot for mean weekly_sales by store type and holiday \\n    mean_sales_by_type_holiday = sales.pivot_table(values='weekly_sales', columns='is_holiday', index='type')\\n\\n    # Print mean_sales_by_type_holiday\\n    print(mean_sales_by_type_holiday) \\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' # Pivot for mean weekly_sales by store type and holiday \n",
    "    mean_sales_by_type_holiday = sales.pivot_table(values='weekly_sales', columns='is_holiday', index='type')\n",
    "\n",
    "    # Print mean_sales_by_type_holiday\n",
    "    print(mean_sales_by_type_holiday) \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" # Print mean weekly_sales by department and type; fill missing values with 0\\nprint(sales.pivot_table(values='weekly_sales',\\n      columns='department', index='type', fill_value=0))\\n \""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' # Print mean weekly_sales by department and type; fill missing values with 0\n",
    "print(sales.pivot_table(values='weekly_sales',\n",
    "      columns='department', index='type', fill_value=0))\n",
    " '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" # Look at temperatures\\nprint(temperatures)\\n\\n# Index temperatures by city\\ntemperatures_ind = temperatures.set_index('city')\\n\\n# Look at temperatures_ind\\nprint(temperatures_ind)\\n\\n# Reset the index, keeping its contents\\nprint(temperatures_ind.reset_index())\\n\\n# Reset the index, dropping its contents\\nprint(temperatures_ind.reset_index(drop=True)) \""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' # Look at temperatures\n",
    "print(temperatures)\n",
    "\n",
    "# Index temperatures by city\n",
    "temperatures_ind = temperatures.set_index('city')\n",
    "\n",
    "# Look at temperatures_ind\n",
    "print(temperatures_ind)\n",
    "\n",
    "# Reset the index, keeping its contents\n",
    "print(temperatures_ind.reset_index())\n",
    "\n",
    "# Reset the index, dropping its contents\n",
    "print(temperatures_ind.reset_index(drop=True)) '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' # Make a list of cities to subset on\\ncities = [\"Moscow\", \"Saint Petersburg\"]\\n\\n# Subset temperatures using square brackets\\nprint(temperatures[temperatures[\"city\"].isin(cities)])\\n\\n# Subset temperatures_ind using .loc[]\\nprint(temperatures_ind.loc[cities]) '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' # Make a list of cities to subset on\n",
    "cities = [\"Moscow\", \"Saint Petersburg\"]\n",
    "\n",
    "# Subset temperatures using square brackets\n",
    "print(temperatures[temperatures[\"city\"].isin(cities)])\n",
    "\n",
    "# Subset temperatures_ind using .loc[]\n",
    "print(temperatures_ind.loc[cities]) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' # Index temperatures by country & city\\ntemperatures_ind = temperatures.set_index([\"country\", \"city\"])\\n\\n# List of tuples: Brazil, Rio De Janeiro & Pakistan, Lahore\\nrows_to_keep = [(\"Brazil\", \"Rio De Janeiro\"), (\"Pakistan\", \"Lahore\")]\\n\\n# Subset for rows to keep\\nprint(temperatures_ind.loc[rows_to_keep]) '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' # Index temperatures by country & city\n",
    "temperatures_ind = temperatures.set_index([\"country\", \"city\"])\n",
    "\n",
    "# List of tuples: Brazil, Rio De Janeiro & Pakistan, Lahore\n",
    "rows_to_keep = [(\"Brazil\", \"Rio De Janeiro\"), (\"Pakistan\", \"Lahore\")]\n",
    "\n",
    "# Subset for rows to keep\n",
    "print(temperatures_ind.loc[rows_to_keep]) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" # Sort temperatures_ind by index values\\nprint(temperatures_ind.sort_index())\\n\\n# Sort temperatures_ind by index values at the city level\\nprint(temperatures_ind.sort_index(level='city'))\\n\\n# Sort temperatures_ind by country then descending city\\nprint(temperatures_ind.sort_index(level=['country', 'city'], ascending=[True, False])) \\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' # Sort temperatures_ind by index values\n",
    "print(temperatures_ind.sort_index())\n",
    "\n",
    "# Sort temperatures_ind by index values at the city level\n",
    "print(temperatures_ind.sort_index(level='city'))\n",
    "\n",
    "# Sort temperatures_ind by country then descending city\n",
    "print(temperatures_ind.sort_index(level=['country', 'city'], ascending=[True, False])) \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" # Sort the index of temperatures_ind\\ntemperatures_srt = temperatures_ind.sort_index()\\n\\n# Subset rows from Pakistan to Russia\\nprint(temperatures_srt.loc['Pakistan':'Russia'])\\n\\n# Try to subset rows from Lahore to Moscow\\nprint(temperatures_srt.loc['Lahore':'Moscow'])\\n\\n# Subset rows from Pakistan, Lahore to Russia, Moscow\\nprint(temperatures_srt.loc[('Pakistan', 'Lahore'):('Russia','Moscow')]) \\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' # Sort the index of temperatures_ind\n",
    "temperatures_srt = temperatures_ind.sort_index()\n",
    "\n",
    "# Subset rows from Pakistan to Russia\n",
    "print(temperatures_srt.loc['Pakistan':'Russia'])\n",
    "\n",
    "# Try to subset rows from Lahore to Moscow\n",
    "print(temperatures_srt.loc['Lahore':'Moscow'])\n",
    "\n",
    "# Subset rows from Pakistan, Lahore to Russia, Moscow\n",
    "print(temperatures_srt.loc[('Pakistan', 'Lahore'):('Russia','Moscow')]) \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' # Subset rows from India, Hyderabad to Iraq, Baghdad\\nprint(temperatures_srt.loc[(\"India\", \"Hyderabad\"):(\"Iraq\", \"Baghdad\")])\\n\\n# Subset columns from date to avg_temp_c\\nprint(temperatures_srt.loc[:, \"date\":\"avg_temp_c\"])\\n\\n# Subset in both directions at once\\nprint(temperatures_srt.loc[(\"India\", \"Hyderabad\"):(\"Iraq\", \"Baghdad\"), \"date\":\"avg_temp_c\"])\\n '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' # Subset rows from India, Hyderabad to Iraq, Baghdad\n",
    "print(temperatures_srt.loc[(\"India\", \"Hyderabad\"):(\"Iraq\", \"Baghdad\")])\n",
    "\n",
    "# Subset columns from date to avg_temp_c\n",
    "print(temperatures_srt.loc[:, \"date\":\"avg_temp_c\"])\n",
    "\n",
    "# Subset in both directions at once\n",
    "print(temperatures_srt.loc[(\"India\", \"Hyderabad\"):(\"Iraq\", \"Baghdad\"), \"date\":\"avg_temp_c\"])\n",
    " '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "93d181ae0537741559a56fe3f4ecb1ffaf114b18a27fd1319b63730f0271173f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
