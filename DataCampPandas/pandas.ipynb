{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.sort_values('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[['seleciona']]\n",
    "# colors = [\"brown\", \"black\", \"tan\"]\n",
    "# condition = dogs[\"color\"].isin(colors)\n",
    "# dogs[condition]\n",
    "# \n",
    "\n",
    "#colors = [\"brown\", \"black\", \"tan\"]\n",
    "#condition = dogs[\"color\"].isin(colors)\n",
    "#dogs[condition]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Mojave Desert states\n",
    "#canu = [\"California\", \"Arizona\", \"Nevada\", \"Utah\"]\n",
    "\n",
    "# Filter for rows in the Mojave Desert states\n",
    "#mojave_homelessness = homelessness[homelessness[\"state\"].isin(canu)]\n",
    "\n",
    "# See the result\n",
    "#print(mojave_homelessness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' homelessness[\"indiv_per_10k\"] = 10000 * homelessness[\"individuals\"] / homelessness[\"state_pop\"] \\n\\n# Subset rows for indiv_per_10k greater than 20\\nhigh_homelessness = homelessness[homelessness[\"indiv_per_10k\"] > 20]\\n\\n# Sort high_homelessness by descending indiv_per_10k\\nhigh_homelessness_srt = high_homelessness.sort_values(\"indiv_per_10k\", ascending=False)\\n\\n# From high_homelessness_srt, select the state and indiv_per_10k cols\\nresult = high_homelessness_srt[[\"state\", \"indiv_per_10k\"]]\\n\\n# See the result\\nprint(result) '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create indiv_per_10k col as homeless individuals per 10k state pop\n",
    "''' homelessness[\"indiv_per_10k\"] = 10000 * homelessness[\"individuals\"] / homelessness[\"state_pop\"] \n",
    "\n",
    "# Subset rows for indiv_per_10k greater than 20\n",
    "high_homelessness = homelessness[homelessness[\"indiv_per_10k\"] > 20]\n",
    "\n",
    "# Sort high_homelessness by descending indiv_per_10k\n",
    "high_homelessness_srt = high_homelessness.sort_values(\"indiv_per_10k\", ascending=False)\n",
    "\n",
    "# From high_homelessness_srt, select the state and indiv_per_10k cols\n",
    "result = high_homelessness_srt[[\"state\", \"indiv_per_10k\"]]\n",
    "\n",
    "# See the result\n",
    "print(result) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    agregação de dados\\n    df[\\'column\\'].agg(function)\\n    \\n    # A custom IQR function\\n    def iqr(column):\\n        return column.quantile(0.75) - column.quantile(0.25)\\n    \\n    # Print IQR of the temperature_c column\\n    print(sales[\"temperature_c\"].agg(iqr))\\n\\n    # A custom IQR function\\n    def iqr(column):\\n        return column.quantile(0.75) - column.quantile(0.25)\\n\\n    # Update to print IQR of temperature_c, fuel_price_usd_per_l, & unemployment\\n    print(sales[[\"temperature_c\", \\'fuel_price_usd_per_l\\', \\'unemployment\\']].agg(iqr))\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    agregação de dados\n",
    "    df['column'].agg(function)\n",
    "    \n",
    "    # A custom IQR function\n",
    "    def iqr(column):\n",
    "        return column.quantile(0.75) - column.quantile(0.25)\n",
    "    \n",
    "    # Print IQR of the temperature_c column\n",
    "    print(sales[\"temperature_c\"].agg(iqr))\n",
    "\n",
    "    # A custom IQR function\n",
    "    def iqr(column):\n",
    "        return column.quantile(0.75) - column.quantile(0.25)\n",
    "\n",
    "    # Update to print IQR of temperature_c, fuel_price_usd_per_l, & unemployment\n",
    "    print(sales[[\"temperature_c\", 'fuel_price_usd_per_l', 'unemployment']].agg(iqr))\n",
    "\n",
    "    print(sales[[\"temperature_c\", \"fuel_price_usd_per_l\", \"unemployment\"]].agg([iqr, np.median]))\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n# Sort sales_1_1 by date\\nsales_1_1 = sales_1_1.sort_values(\"date\")\\n\\n# Get the cumulative sum of weekly_sales, add as cum_weekly_sales col\\nsales_1_1[\"cum_weekly_sales\"] = sales_1_1[\"weekly_sales\"].cumsum()\\n\\n# Get the cumulative max of weekly_sales, add as cum_max_sales col\\nsales_1_1[\"cum_max_sales\"] = sales_1_1[\"weekly_sales\"].cummax()\\n\\n# See the columns you calculated\\nprint(sales_1_1[[\"date\", \"weekly_sales\", \"cum_weekly_sales\", \"cum_max_sales\"]])\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "# Sort sales_1_1 by date\n",
    "sales_1_1 = sales_1_1.sort_values(\"date\")\n",
    "\n",
    "# Get the cumulative sum of weekly_sales, add as cum_weekly_sales col\n",
    "sales_1_1[\"cum_weekly_sales\"] = sales_1_1[\"weekly_sales\"].cumsum()\n",
    "\n",
    "# Get the cumulative max of weekly_sales, add as cum_max_sales col\n",
    "sales_1_1[\"cum_max_sales\"] = sales_1_1[\"weekly_sales\"].cummax()\n",
    "\n",
    "# See the columns you calculated\n",
    "print(sales_1_1[[\"date\", \"weekly_sales\", \"cum_weekly_sales\", \"cum_max_sales\"]])\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\n    # Drop duplicate store/type combinations\\n    store_types = sales.drop_duplicates(subset='store')\\n    print(store_types.head())\\n\\n    # Drop duplicate store/department combinations\\n    store_depts = sales.drop_duplicates(subset=['department', 'store'])\\n    print(store_depts.head())\\n\\n    # Subset the rows where is_holiday is True and drop duplicate dates\\n    holiday_dates = sales[sales['is_holiday']].drop_duplicates(subset='date')\\n\\n    # Print date col of holiday_dates\\n    print(holiday_dates.head())\\n\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "    # Drop duplicate store/type combinations\n",
    "    store_types = sales.drop_duplicates(subset='store')\n",
    "    print(store_types.head())\n",
    "\n",
    "    # Drop duplicate store/department combinations\n",
    "    store_depts = sales.drop_duplicates(subset=['department', 'store'])\n",
    "    print(store_depts.head())\n",
    "\n",
    "    # Subset the rows where is_holiday is True and drop duplicate dates\n",
    "    holiday_dates = sales[sales['is_holiday']].drop_duplicates(subset='date')\n",
    "\n",
    "    # Print date col of holiday_dates\n",
    "    print(holiday_dates.head())\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\n    # Count the number of stores of each type\\n    store_counts = store_types['type'].value_counts()\\n    print(store_counts)\\n\\n    # Get the proportion of stores of each type\\n    store_props = store_types['type'].value_counts(normalize=True)\\n    print(store_props)\\n\\n    # Count the number of each department number and sort\\n    dept_counts_sorted = store_depts['department'].value_counts(sort=True)\\n    print(dept_counts_sorted)\\n\\n    # Get the proportion of departments of each number and sort\\n    dept_props_sorted = store_depts['department'].value_counts(sort=True, normalize=True)\\n    print(dept_props_sorted)\\n\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "    # Count the number of stores of each type\n",
    "    store_counts = store_types['type'].value_counts()\n",
    "    print(store_counts)\n",
    "\n",
    "    # Get the proportion of stores of each type\n",
    "    store_props = store_types['type'].value_counts(normalize=True)\n",
    "    print(store_props)\n",
    "\n",
    "    # Count the number of each department number and sort\n",
    "    dept_counts_sorted = store_depts['department'].value_counts(sort=True)\n",
    "    print(dept_counts_sorted)\n",
    "\n",
    "    # Get the proportion of departments of each number and sort\n",
    "    dept_props_sorted = store_depts['department'].value_counts(sort=True, normalize=True)\n",
    "    print(dept_props_sorted)\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n    # Calc total weekly sales\\n    sales_all = sales[\"weekly_sales\"].sum()\\n\\n    # Subset for type A stores, calc total weekly sales\\n    sales_A = sales[sales[\"type\"] == \"A\"][\"weekly_sales\"].sum()\\n\\n    # Subset for type B stores, calc total weekly sales\\n    sales_B = sales[sales[\\'type\\']== \\'B\\'][\\'weekly_sales\\'].sum()\\n\\n    # Subset for type C stores, calc total weekly sales\\n    sales_C = sales[sales[\\'type\\']== \\'C\\'][\\'weekly_sales\\'].sum()\\n\\n    # Get proportion for each type\\n    sales_propn_by_type = [sales_A, sales_B, sales_C] / sales_all\\n    print(sales_propn_by_type)\\n\\n   # From previous step\\n    sales_by_type = sales.groupby(\"type\")[\"weekly_sales\"].sum()\\n\\n    # Group by type and is_holiday; calc total weekly sales\\n    sales_by_type_is_holiday = sales.groupby([\"type\", \"is_holiday\"])[\"weekly_sales\"].sum()\\n    print(sales_by_type_is_holiday)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "    # Calc total weekly sales\n",
    "    sales_all = sales[\"weekly_sales\"].sum()\n",
    "\n",
    "    # Subset for type A stores, calc total weekly sales\n",
    "    sales_A = sales[sales[\"type\"] == \"A\"][\"weekly_sales\"].sum()\n",
    "\n",
    "    # Subset for type B stores, calc total weekly sales\n",
    "    sales_B = sales[sales['type']== 'B']['weekly_sales'].sum()\n",
    "\n",
    "    # Subset for type C stores, calc total weekly sales\n",
    "    sales_C = sales[sales['type']== 'C']['weekly_sales'].sum()\n",
    "\n",
    "    # Get proportion for each type\n",
    "    sales_propn_by_type = [sales_A, sales_B, sales_C] / sales_all\n",
    "    print(sales_propn_by_type)\n",
    "\n",
    "   # From previous step\n",
    "    sales_by_type = sales.groupby(\"type\")[\"weekly_sales\"].sum()\n",
    "\n",
    "    # Group by type and is_holiday; calc total weekly sales\n",
    "    sales_by_type_is_holiday = sales.groupby([\"type\", \"is_holiday\"])[\"weekly_sales\"].sum()\n",
    "    print(sales_by_type_is_holiday)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n    # Import numpy with the alias np\\n    import numpy as np\\n\\n    # For each store type, aggregate weekly_sales: get min, max, mean, and median\\n    sales_stats = sales.groupby(\"type\")[\"weekly_sales\"].agg([np.min, np.max, np.mean, np.median])\\n\\n    # Print sales_stats\\n    print(sales_stats)\\n\\n    # For each store type, aggregate unemployment and fuel_price_usd_per_l: get min, max, mean, and median\\n    unemp_fuel_stats = sales.groupby(\"type\")[[\"unemployment\", \"fuel_price_usd_per_l\"]].agg([np.min, np.max, np.mean, np.median])\\n\\n    # Print unemp_fuel_stats\\n    print(unemp_fuel_stats)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "    # Import numpy with the alias np\n",
    "    import numpy as np\n",
    "\n",
    "    # For each store type, aggregate weekly_sales: get min, max, mean, and median\n",
    "    sales_stats = sales.groupby(\"type\")[\"weekly_sales\"].agg([np.min, np.max, np.mean, np.median])\n",
    "\n",
    "    # Print sales_stats\n",
    "    print(sales_stats)\n",
    "\n",
    "    # For each store type, aggregate unemployment and fuel_price_usd_per_l: get min, max, mean, and median\n",
    "    unemp_fuel_stats = sales.groupby(\"type\")[[\"unemployment\", \"fuel_price_usd_per_l\"]].agg([np.min, np.max, np.mean, np.median])\n",
    "\n",
    "    # Print unemp_fuel_stats\n",
    "    print(unemp_fuel_stats)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "93d181ae0537741559a56fe3f4ecb1ffaf114b18a27fd1319b63730f0271173f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
