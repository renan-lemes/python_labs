{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.sort_values('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[['seleciona']]\n",
    "# colors = [\"brown\", \"black\", \"tan\"]\n",
    "# condition = dogs[\"color\"].isin(colors)\n",
    "# dogs[condition]\n",
    "# \n",
    "\n",
    "#colors = [\"brown\", \"black\", \"tan\"]\n",
    "#condition = dogs[\"color\"].isin(colors)\n",
    "#dogs[condition]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Mojave Desert states\n",
    "#canu = [\"California\", \"Arizona\", \"Nevada\", \"Utah\"]\n",
    "\n",
    "# Filter for rows in the Mojave Desert states\n",
    "#mojave_homelessness = homelessness[homelessness[\"state\"].isin(canu)]\n",
    "\n",
    "# See the result\n",
    "#print(mojave_homelessness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' homelessness[\"indiv_per_10k\"] = 10000 * homelessness[\"individuals\"] / homelessness[\"state_pop\"] \\n\\n# Subset rows for indiv_per_10k greater than 20\\nhigh_homelessness = homelessness[homelessness[\"indiv_per_10k\"] > 20]\\n\\n# Sort high_homelessness by descending indiv_per_10k\\nhigh_homelessness_srt = high_homelessness.sort_values(\"indiv_per_10k\", ascending=False)\\n\\n# From high_homelessness_srt, select the state and indiv_per_10k cols\\nresult = high_homelessness_srt[[\"state\", \"indiv_per_10k\"]]\\n\\n# See the result\\nprint(result) '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create indiv_per_10k col as homeless individuals per 10k state pop\n",
    "''' homelessness[\"indiv_per_10k\"] = 10000 * homelessness[\"individuals\"] / homelessness[\"state_pop\"] \n",
    "\n",
    "# Subset rows for indiv_per_10k greater than 20\n",
    "high_homelessness = homelessness[homelessness[\"indiv_per_10k\"] > 20]\n",
    "\n",
    "# Sort high_homelessness by descending indiv_per_10k\n",
    "high_homelessness_srt = high_homelessness.sort_values(\"indiv_per_10k\", ascending=False)\n",
    "\n",
    "# From high_homelessness_srt, select the state and indiv_per_10k cols\n",
    "result = high_homelessness_srt[[\"state\", \"indiv_per_10k\"]]\n",
    "\n",
    "# See the result\n",
    "print(result) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    agregação de dados\\n    df[\\'column\\'].agg(function)\\n    \\n    # A custom IQR function\\n    def iqr(column):\\n        return column.quantile(0.75) - column.quantile(0.25)\\n    \\n    # Print IQR of the temperature_c column\\n    print(sales[\"temperature_c\"].agg(iqr))\\n\\n    # A custom IQR function\\n    def iqr(column):\\n        return column.quantile(0.75) - column.quantile(0.25)\\n\\n    # Update to print IQR of temperature_c, fuel_price_usd_per_l, & unemployment\\n    print(sales[[\"temperature_c\", \\'fuel_price_usd_per_l\\', \\'unemployment\\']].agg(iqr))\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    agregação de dados\n",
    "    df['column'].agg(function)\n",
    "    \n",
    "    # A custom IQR function\n",
    "    def iqr(column):\n",
    "        return column.quantile(0.75) - column.quantile(0.25)\n",
    "    \n",
    "    # Print IQR of the temperature_c column\n",
    "    print(sales[\"temperature_c\"].agg(iqr))\n",
    "\n",
    "    # A custom IQR function\n",
    "    def iqr(column):\n",
    "        return column.quantile(0.75) - column.quantile(0.25)\n",
    "\n",
    "    # Update to print IQR of temperature_c, fuel_price_usd_per_l, & unemployment\n",
    "    print(sales[[\"temperature_c\", 'fuel_price_usd_per_l', 'unemployment']].agg(iqr))\n",
    "\n",
    "    print(sales[[\"temperature_c\", \"fuel_price_usd_per_l\", \"unemployment\"]].agg([iqr, np.median]))\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n# Sort sales_1_1 by date\\nsales_1_1 = sales_1_1.sort_values(\"date\")\\n\\n# Get the cumulative sum of weekly_sales, add as cum_weekly_sales col\\nsales_1_1[\"cum_weekly_sales\"] = sales_1_1[\"weekly_sales\"].cumsum()\\n\\n# Get the cumulative max of weekly_sales, add as cum_max_sales col\\nsales_1_1[\"cum_max_sales\"] = sales_1_1[\"weekly_sales\"].cummax()\\n\\n# See the columns you calculated\\nprint(sales_1_1[[\"date\", \"weekly_sales\", \"cum_weekly_sales\", \"cum_max_sales\"]])\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "# Sort sales_1_1 by date\n",
    "sales_1_1 = sales_1_1.sort_values(\"date\")\n",
    "\n",
    "# Get the cumulative sum of weekly_sales, add as cum_weekly_sales col\n",
    "sales_1_1[\"cum_weekly_sales\"] = sales_1_1[\"weekly_sales\"].cumsum()\n",
    "\n",
    "# Get the cumulative max of weekly_sales, add as cum_max_sales col\n",
    "sales_1_1[\"cum_max_sales\"] = sales_1_1[\"weekly_sales\"].cummax()\n",
    "\n",
    "# See the columns you calculated\n",
    "print(sales_1_1[[\"date\", \"weekly_sales\", \"cum_weekly_sales\", \"cum_max_sales\"]])\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\n    # Drop duplicate store/type combinations\\n    store_types = sales.drop_duplicates(subset='store')\\n    print(store_types.head())\\n\\n    # Drop duplicate store/department combinations\\n    store_depts = sales.drop_duplicates(subset=['department', 'store'])\\n    print(store_depts.head())\\n\\n    # Subset the rows where is_holiday is True and drop duplicate dates\\n    holiday_dates = sales[sales['is_holiday']].drop_duplicates(subset='date')\\n\\n    # Print date col of holiday_dates\\n    print(holiday_dates.head())\\n\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "    # Drop duplicate store/type combinations\n",
    "    store_types = sales.drop_duplicates(subset='store')\n",
    "    print(store_types.head())\n",
    "\n",
    "    # Drop duplicate store/department combinations\n",
    "    store_depts = sales.drop_duplicates(subset=['department', 'store'])\n",
    "    print(store_depts.head())\n",
    "\n",
    "    # Subset the rows where is_holiday is True and drop duplicate dates\n",
    "    holiday_dates = sales[sales['is_holiday']].drop_duplicates(subset='date')\n",
    "\n",
    "    # Print date col of holiday_dates\n",
    "    print(holiday_dates.head())\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\n    # Count the number of stores of each type\\n    store_counts = store_types['type'].value_counts()\\n    print(store_counts)\\n\\n    # Get the proportion of stores of each type\\n    store_props = store_types['type'].value_counts(normalize=True)\\n    print(store_props)\\n\\n    # Count the number of each department number and sort\\n    dept_counts_sorted = store_depts['department'].value_counts(sort=True)\\n    print(dept_counts_sorted)\\n\\n    # Get the proportion of departments of each number and sort\\n    dept_props_sorted = store_depts['department'].value_counts(sort=True, normalize=True)\\n    print(dept_props_sorted)\\n\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "    # Count the number of stores of each type\n",
    "    store_counts = store_types['type'].value_counts()\n",
    "    print(store_counts)\n",
    "\n",
    "    # Get the proportion of stores of each type\n",
    "    store_props = store_types['type'].value_counts(normalize=True)\n",
    "    print(store_props)\n",
    "\n",
    "    # Count the number of each department number and sort\n",
    "    dept_counts_sorted = store_depts['department'].value_counts(sort=True)\n",
    "    print(dept_counts_sorted)\n",
    "\n",
    "    # Get the proportion of departments of each number and sort\n",
    "    dept_props_sorted = store_depts['department'].value_counts(sort=True, normalize=True)\n",
    "    print(dept_props_sorted)\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n    # Calc total weekly sales\\n    sales_all = sales[\"weekly_sales\"].sum()\\n\\n    # Subset for type A stores, calc total weekly sales\\n    sales_A = sales[sales[\"type\"] == \"A\"][\"weekly_sales\"].sum()\\n\\n    # Subset for type B stores, calc total weekly sales\\n    sales_B = sales[sales[\\'type\\']== \\'B\\'][\\'weekly_sales\\'].sum()\\n\\n    # Subset for type C stores, calc total weekly sales\\n    sales_C = sales[sales[\\'type\\']== \\'C\\'][\\'weekly_sales\\'].sum()\\n\\n    # Get proportion for each type\\n    sales_propn_by_type = [sales_A, sales_B, sales_C] / sales_all\\n    print(sales_propn_by_type)\\n\\n   # From previous step\\n    sales_by_type = sales.groupby(\"type\")[\"weekly_sales\"].sum()\\n\\n    # Group by type and is_holiday; calc total weekly sales\\n    sales_by_type_is_holiday = sales.groupby([\"type\", \"is_holiday\"])[\"weekly_sales\"].sum()\\n    print(sales_by_type_is_holiday)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "    # Calc total weekly sales\n",
    "    sales_all = sales[\"weekly_sales\"].sum()\n",
    "\n",
    "    # Subset for type A stores, calc total weekly sales\n",
    "    sales_A = sales[sales[\"type\"] == \"A\"][\"weekly_sales\"].sum()\n",
    "\n",
    "    # Subset for type B stores, calc total weekly sales\n",
    "    sales_B = sales[sales['type']== 'B']['weekly_sales'].sum()\n",
    "\n",
    "    # Subset for type C stores, calc total weekly sales\n",
    "    sales_C = sales[sales['type']== 'C']['weekly_sales'].sum()\n",
    "\n",
    "    # Get proportion for each type\n",
    "    sales_propn_by_type = [sales_A, sales_B, sales_C] / sales_all\n",
    "    print(sales_propn_by_type)\n",
    "\n",
    "   # From previous step\n",
    "    sales_by_type = sales.groupby(\"type\")[\"weekly_sales\"].sum()\n",
    "\n",
    "    # Group by type and is_holiday; calc total weekly sales\n",
    "    sales_by_type_is_holiday = sales.groupby([\"type\", \"is_holiday\"])[\"weekly_sales\"].sum()\n",
    "    print(sales_by_type_is_holiday)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n    # Import numpy with the alias np\\n    import numpy as np\\n\\n    # For each store type, aggregate weekly_sales: get min, max, mean, and median\\n    sales_stats = sales.groupby(\"type\")[\"weekly_sales\"].agg([np.min, np.max, np.mean, np.median])\\n\\n    # Print sales_stats\\n    print(sales_stats)\\n\\n    # For each store type, aggregate unemployment and fuel_price_usd_per_l: get min, max, mean, and median\\n    unemp_fuel_stats = sales.groupby(\"type\")[[\"unemployment\", \"fuel_price_usd_per_l\"]].agg([np.min, np.max, np.mean, np.median])\\n\\n    # Print unemp_fuel_stats\\n    print(unemp_fuel_stats)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "    # Import numpy with the alias np\n",
    "    import numpy as np\n",
    "\n",
    "    # For each store type, aggregate weekly_sales: get min, max, mean, and median\n",
    "    sales_stats = sales.groupby(\"type\")[\"weekly_sales\"].agg([np.min, np.max, np.mean, np.median])\n",
    "\n",
    "    # Print sales_stats\n",
    "    print(sales_stats)\n",
    "\n",
    "    # For each store type, aggregate unemployment and fuel_price_usd_per_l: get min, max, mean, and median\n",
    "    unemp_fuel_stats = sales.groupby(\"type\")[[\"unemployment\", \"fuel_price_usd_per_l\"]].agg([np.min, np.max, np.mean, np.median])\n",
    "\n",
    "    # Print unemp_fuel_stats\n",
    "    print(unemp_fuel_stats)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\n    # Import NumPy as np\\n    import numpy as np\\n\\n    # Pivot for mean and median weekly_sales for each store type\\n    mean_med_sales_by_type = sales.pivot_table(values='weekly_sales',index='type', aggfunc=[np.median, np.mean])\\n\\n    # Print mean_med_sales_by_type\\n    print(mean_med_sales_by_type)\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "    # Import NumPy as np\n",
    "    import numpy as np\n",
    "\n",
    "    # Pivot for mean and median weekly_sales for each store type\n",
    "    mean_med_sales_by_type = sales.pivot_table(values='weekly_sales',index='type', aggfunc=[np.median, np.mean])\n",
    "\n",
    "    # Print mean_med_sales_by_type\n",
    "    print(mean_med_sales_by_type)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" mean_sales_by_type_holiday = sales.pivot_table(\\n    values=['weekly_sales', 'is_holiday'], index='type')\\n\\n    # Print mean_sales_by_type_holiday\\n    print(mean_sales_by_type_holiday) \\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' mean_sales_by_type_holiday = sales.pivot_table(\n",
    "    values=['weekly_sales', 'is_holiday'], index='type')\n",
    "\n",
    "    # Print mean_sales_by_type_holiday\n",
    "    print(mean_sales_by_type_holiday) \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" # Pivot for mean weekly_sales by store type and holiday \\n    mean_sales_by_type_holiday = sales.pivot_table(values='weekly_sales', columns='is_holiday', index='type')\\n\\n    # Print mean_sales_by_type_holiday\\n    print(mean_sales_by_type_holiday) \\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' # Pivot for mean weekly_sales by store type and holiday \n",
    "    mean_sales_by_type_holiday = sales.pivot_table(values='weekly_sales', columns='is_holiday', index='type')\n",
    "\n",
    "    # Print mean_sales_by_type_holiday\n",
    "    print(mean_sales_by_type_holiday) \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" # Print mean weekly_sales by department and type; fill missing values with 0\\nprint(sales.pivot_table(values='weekly_sales',\\n      columns='department', index='type', fill_value=0))\\n \""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' # Print mean weekly_sales by department and type; fill missing values with 0\n",
    "print(sales.pivot_table(values='weekly_sales',\n",
    "      columns='department', index='type', fill_value=0))\n",
    " '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" # Look at temperatures\\nprint(temperatures)\\n\\n# Index temperatures by city\\ntemperatures_ind = temperatures.set_index('city')\\n\\n# Look at temperatures_ind\\nprint(temperatures_ind)\\n\\n# Reset the index, keeping its contents\\nprint(temperatures_ind.reset_index())\\n\\n# Reset the index, dropping its contents\\nprint(temperatures_ind.reset_index(drop=True)) \""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' # Look at temperatures\n",
    "print(temperatures)\n",
    "\n",
    "# Index temperatures by city\n",
    "temperatures_ind = temperatures.set_index('city')\n",
    "\n",
    "# Look at temperatures_ind\n",
    "print(temperatures_ind)\n",
    "\n",
    "# Reset the index, keeping its contents\n",
    "print(temperatures_ind.reset_index())\n",
    "\n",
    "# Reset the index, dropping its contents\n",
    "print(temperatures_ind.reset_index(drop=True)) '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' # Make a list of cities to subset on\\ncities = [\"Moscow\", \"Saint Petersburg\"]\\n\\n# Subset temperatures using square brackets\\nprint(temperatures[temperatures[\"city\"].isin(cities)])\\n\\n# Subset temperatures_ind using .loc[]\\nprint(temperatures_ind.loc[cities]) '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' # Make a list of cities to subset on\n",
    "cities = [\"Moscow\", \"Saint Petersburg\"]\n",
    "\n",
    "# Subset temperatures using square brackets\n",
    "print(temperatures[temperatures[\"city\"].isin(cities)])\n",
    "\n",
    "# Subset temperatures_ind using .loc[]\n",
    "print(temperatures_ind.loc[cities]) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' # Index temperatures by country & city\\ntemperatures_ind = temperatures.set_index([\"country\", \"city\"])\\n\\n# List of tuples: Brazil, Rio De Janeiro & Pakistan, Lahore\\nrows_to_keep = [(\"Brazil\", \"Rio De Janeiro\"), (\"Pakistan\", \"Lahore\")]\\n\\n# Subset for rows to keep\\nprint(temperatures_ind.loc[rows_to_keep]) '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' # Index temperatures by country & city\n",
    "temperatures_ind = temperatures.set_index([\"country\", \"city\"])\n",
    "\n",
    "# List of tuples: Brazil, Rio De Janeiro & Pakistan, Lahore\n",
    "rows_to_keep = [(\"Brazil\", \"Rio De Janeiro\"), (\"Pakistan\", \"Lahore\")]\n",
    "\n",
    "# Subset for rows to keep\n",
    "print(temperatures_ind.loc[rows_to_keep]) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" # Sort temperatures_ind by index values\\nprint(temperatures_ind.sort_index())\\n\\n# Sort temperatures_ind by index values at the city level\\nprint(temperatures_ind.sort_index(level='city'))\\n\\n# Sort temperatures_ind by country then descending city\\nprint(temperatures_ind.sort_index(level=['country', 'city'], ascending=[True, False])) \\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' # Sort temperatures_ind by index values\n",
    "print(temperatures_ind.sort_index())\n",
    "\n",
    "# Sort temperatures_ind by index values at the city level\n",
    "print(temperatures_ind.sort_index(level='city'))\n",
    "\n",
    "# Sort temperatures_ind by country then descending city\n",
    "print(temperatures_ind.sort_index(level=['country', 'city'], ascending=[True, False])) \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" # Sort the index of temperatures_ind\\ntemperatures_srt = temperatures_ind.sort_index()\\n\\n# Subset rows from Pakistan to Russia\\nprint(temperatures_srt.loc['Pakistan':'Russia'])\\n\\n# Try to subset rows from Lahore to Moscow\\nprint(temperatures_srt.loc['Lahore':'Moscow'])\\n\\n# Subset rows from Pakistan, Lahore to Russia, Moscow\\nprint(temperatures_srt.loc[('Pakistan', 'Lahore'):('Russia','Moscow')]) \\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' # Sort the index of temperatures_ind\n",
    "temperatures_srt = temperatures_ind.sort_index()\n",
    "\n",
    "# Subset rows from Pakistan to Russia\n",
    "print(temperatures_srt.loc['Pakistan':'Russia'])\n",
    "\n",
    "# Try to subset rows from Lahore to Moscow\n",
    "print(temperatures_srt.loc['Lahore':'Moscow'])\n",
    "\n",
    "# Subset rows from Pakistan, Lahore to Russia, Moscow\n",
    "print(temperatures_srt.loc[('Pakistan', 'Lahore'):('Russia','Moscow')]) \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' # Subset rows from India, Hyderabad to Iraq, Baghdad\\nprint(temperatures_srt.loc[(\"India\", \"Hyderabad\"):(\"Iraq\", \"Baghdad\")])\\n\\n# Subset columns from date to avg_temp_c\\nprint(temperatures_srt.loc[:, \"date\":\"avg_temp_c\"])\\n\\n# Subset in both directions at once\\nprint(temperatures_srt.loc[(\"India\", \"Hyderabad\"):(\"Iraq\", \"Baghdad\"), \"date\":\"avg_temp_c\"])\\n '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' # Subset rows from India, Hyderabad to Iraq, Baghdad\n",
    "print(temperatures_srt.loc[(\"India\", \"Hyderabad\"):(\"Iraq\", \"Baghdad\")])\n",
    "\n",
    "# Subset columns from date to avg_temp_c\n",
    "print(temperatures_srt.loc[:, \"date\":\"avg_temp_c\"])\n",
    "\n",
    "# Subset in both directions at once\n",
    "print(temperatures_srt.loc[(\"India\", \"Hyderabad\"):(\"Iraq\", \"Baghdad\"), \"date\":\"avg_temp_c\"])\n",
    " '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' # Use Boolean conditions to subset temperatures for rows in 2010 and 2011\\ntemperatures_bool = temperatures[(temperatures[\"date\"] >= \"2010-01-01\") & (temperatures[\"date\"] <= \"2011-12-31\")]\\nprint(temperatures_bool)\\n\\n# Set date as the index and sort the index\\ntemperatures_ind = temperatures.set_index(\"date\").sort_index()\\n\\n# Use .loc[] to subset temperatures_ind for rows in 2010 and 2011\\nprint(temperatures_ind.loc[\"2010\":\"2011\"])\\n\\n# Use .loc[] to subset temperatures_ind for rows from Aug 2010 to Feb 2011\\nprint(temperatures_ind.loc[\"2010-08\":\"2011-02\"]) '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' # Use Boolean conditions to subset temperatures for rows in 2010 and 2011\n",
    "temperatures_bool = temperatures[(temperatures[\"date\"] >= \"2010-01-01\") & (temperatures[\"date\"] <= \"2011-12-31\")]\n",
    "print(temperatures_bool)\n",
    "\n",
    "# Set date as the index and sort the index\n",
    "temperatures_ind = temperatures.set_index(\"date\").sort_index()\n",
    "\n",
    "# Use .loc[] to subset temperatures_ind for rows in 2010 and 2011\n",
    "print(temperatures_ind.loc[\"2010\":\"2011\"])\n",
    "\n",
    "# Use .loc[] to subset temperatures_ind for rows from Aug 2010 to Feb 2011\n",
    "print(temperatures_ind.loc[\"2010-08\":\"2011-02\"]) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" # Add a year column to temperatures\\ntemperatures['year'] = temperatures['date'].dt.year\\n\\n# Pivot avg_temp_c by country and city vs year\\ntemp_by_country_city_vs_year = temperatures.pivot_table('avg_temp_c', index=['country', 'city'], columns='year')\\n\\n# See the result\\nprint(temp_by_country_city_vs_year) \""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' # Add a year column to temperatures\n",
    "temperatures['year'] = temperatures['date'].dt.year\n",
    "\n",
    "# Pivot avg_temp_c by country and city vs year\n",
    "temp_by_country_city_vs_year = temperatures.pivot_table('avg_temp_c', index=['country', 'city'], columns='year')\n",
    "\n",
    "# See the result\n",
    "print(temp_by_country_city_vs_year) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' # Subset for Egypt to India\\ntemp_by_country_city_vs_year.loc[\"Egypt\":\"India\"]\\n\\n# Subset for Egypt, Cairo to India, Delhi\\ntemp_by_country_city_vs_year.loc[(\"Egypt\", \"Cairo\"):(\"India\", \"Delhi\")]\\n\\n# Subset in both directions at once\\ntemp_by_country_city_vs_year.loc[(\"Egypt\", \"Cairo\"):(\"India\", \"Delhi\"), \"2005\":\"2010\"] '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' # Subset for Egypt to India\n",
    "temp_by_country_city_vs_year.loc[\"Egypt\":\"India\"]\n",
    "\n",
    "# Subset for Egypt, Cairo to India, Delhi\n",
    "temp_by_country_city_vs_year.loc[(\"Egypt\", \"Cairo\"):(\"India\", \"Delhi\")]\n",
    "\n",
    "# Subset in both directions at once\n",
    "temp_by_country_city_vs_year.loc[(\"Egypt\", \"Cairo\"):(\"India\", \"Delhi\"), \"2005\":\"2010\"] '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' # Get the worldwide mean temp by year\\nmean_temp_by_year = temp_by_country_city_vs_year.mean()\\n\\n# Filter for the year that had the highest mean temp\\nprint(mean_temp_by_year[mean_temp_by_year == mean_temp_by_year.max()])\\n\\n# Get the mean temp by city\\nmean_temp_by_city = temp_by_country_city_vs_year.mean(axis=\"columns\")\\n\\n# Filter for the city that had the lowest mean temp\\nprint(mean_temp_by_city[mean_temp_by_city == mean_temp_by_city.min()]) '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' # Get the worldwide mean temp by year\n",
    "mean_temp_by_year = temp_by_country_city_vs_year.mean()\n",
    "\n",
    "# Filter for the year that had the highest mean temp\n",
    "print(mean_temp_by_year[mean_temp_by_year == mean_temp_by_year.max()])\n",
    "\n",
    "# Get the mean temp by city\n",
    "mean_temp_by_city = temp_by_country_city_vs_year.mean(axis=\"columns\")\n",
    "\n",
    "# Filter for the city that had the lowest mean temp\n",
    "print(mean_temp_by_city[mean_temp_by_city == mean_temp_by_city.min()]) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" # Import matplotlib.pyplot with alias plt\\nimport matplotlib.pyplot as plt\\n\\n# Get the total number of avocados sold on each date\\nnb_sold_by_date = avocados.groupby('date')['nb_sold'].sum()\\n\\n# Create a line plot of the number of avocados sold by date\\nnb_sold_by_date.plot(kind='line')\\n\\n# Show the plot\\nplt.show() \""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' # Import matplotlib.pyplot with alias plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the total number of avocados sold on each date\n",
    "nb_sold_by_date = avocados.groupby('date')['nb_sold'].sum()\n",
    "\n",
    "# Create a line plot of the number of avocados sold by date\n",
    "nb_sold_by_date.plot(kind='line')\n",
    "\n",
    "# Show the plot\n",
    "plt.show() '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n# Modify bins to 20\\navocados[avocados[\"type\"] == \"conventional\"][\"avg_price\"].hist(alpha=0.5, bins=20)\\n\\n# Modify bins to 20\\navocados[avocados[\"type\"] == \"organic\"][\"avg_price\"].hist(alpha=0.5, bins=20)\\n\\n# Add a legend\\nplt.legend([\"conventional\", \"organic\"])\\n\\n# Show the plot\\nplt.show()\\n\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "# Modify bins to 20\n",
    "avocados[avocados[\"type\"] == \"conventional\"][\"avg_price\"].hist(alpha=0.5, bins=20)\n",
    "\n",
    "# Modify bins to 20\n",
    "avocados[avocados[\"type\"] == \"organic\"][\"avg_price\"].hist(alpha=0.5, bins=20)\n",
    "\n",
    "# Add a legend\n",
    "plt.legend([\"conventional\", \"organic\"])\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\n# Import matplotlib.pyplot with alias plt\\nimport matplotlib.pyplot as plt\\n\\n# Check individual values for missing values\\nprint(avocados_2016.isna().sum())\\n\\n# Check each column for missing values\\nprint(avocados_2016.isna().any())\\n\\n# Bar plot of missing values by variable\\navocados_2016.isna().sum().plot(kind='bar')\\n\\n# Show plot\\nplt.show() \\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "# Import matplotlib.pyplot with alias plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check individual values for missing values\n",
    "print(avocados_2016.isna().sum())\n",
    "\n",
    "# Check each column for missing values\n",
    "print(avocados_2016.isna().any())\n",
    "\n",
    "# Bar plot of missing values by variable\n",
    "avocados_2016.isna().sum().plot(kind='bar')\n",
    "\n",
    "# Show plot\n",
    "plt.show() \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\n# Create a list of dictionaries with new data\\navocados_list = [\\n    {'date': '2019-11-03', 'small_sold': 10376832, 'large_sold': 7835071},\\n    {'date': '2019-11-10', 'small_sold': 10717154, 'large_sold': 8561348},\\n]\\n\\n# Convert list into DataFrame\\navocados_2019 = pd.DataFrame(avocados_list)\\n\\n# Print the new DataFrame\\nprint(avocados_2019) \\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "# Create a list of dictionaries with new data\n",
    "avocados_list = [\n",
    "    {'date': '2019-11-03', 'small_sold': 10376832, 'large_sold': 7835071},\n",
    "    {'date': '2019-11-10', 'small_sold': 10717154, 'large_sold': 8561348},\n",
    "]\n",
    "\n",
    "# Convert list into DataFrame\n",
    "avocados_2019 = pd.DataFrame(avocados_list)\n",
    "\n",
    "# Print the new DataFrame\n",
    "print(avocados_2019) \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n# Create a dictionary of lists with new data\\navocados_dict = {\\n  \"date\": [\\'2019-11-17\\', \\'2019-12-01\\'],\\n  \"small_sold\": [10859987, 9291631],\\n  \"large_sold\": [7674135, 6238096]\\n}\\n\\n# Convert dictionary into DataFrame\\navocados_2019 = pd.DataFrame(avocados_dict)\\n\\n# Print the new DataFrame\\nprint(avocados_2019)\\n '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "# Create a dictionary of lists with new data\n",
    "avocados_dict = {\n",
    "  \"date\": ['2019-11-17', '2019-12-01'],\n",
    "  \"small_sold\": [10859987, 9291631],\n",
    "  \"large_sold\": [7674135, 6238096]\n",
    "}\n",
    "\n",
    "# Convert dictionary into DataFrame\n",
    "avocados_2019 = pd.DataFrame(avocados_dict)\n",
    "\n",
    "# Print the new DataFrame\n",
    "print(avocados_2019)\n",
    " '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\n# Create airline_totals_sorted\\nairline_totals_sorted = airline_totals.sort_values('bumps_per_10k',ascending=False)\\n\\n# Print airline_totals_sorted\\nprint(airline_totals_sorted)\\n\\n# Save as airline_totals_sorted.csv\\nairline_totals_sorted.to_csv('airline_totals_sorted.csv') \\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "# Create airline_totals_sorted\n",
    "airline_totals_sorted = airline_totals.sort_values('bumps_per_10k',ascending=False)\n",
    "\n",
    "# Print airline_totals_sorted\n",
    "print(airline_totals_sorted)\n",
    "\n",
    "# Save as airline_totals_sorted.csv\n",
    "airline_totals_sorted.to_csv('airline_totals_sorted.csv') \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "93d181ae0537741559a56fe3f4ecb1ffaf114b18a27fd1319b63730f0271173f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
